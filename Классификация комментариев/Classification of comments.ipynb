{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Импорт-модулей-и--библиотек\" data-toc-modified-id=\"Импорт-модулей-и--библиотек-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Импорт модулей и  библиотек</a></span></li><li><span><a href=\"#Загрузка-данных\" data-toc-modified-id=\"Загрузка-данных-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Загрузка данных</a></span></li><li><span><a href=\"#Лемматизация\" data-toc-modified-id=\"Лемматизация-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Лемматизация</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Разделение-на-выборки\" data-toc-modified-id=\"Разделение-на-выборки-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Разделение на выборки</a></span></li><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>TF-IDF</a></span></li><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#RandomForestClassifier\" data-toc-modified-id=\"RandomForestClassifier-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>RandomForestClassifier</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт модулей и  библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "  import sys\n",
      "/opt/conda/lib/python3.7/site-packages/tqdm/std.py:703: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit, cross_val_score, KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.898321\n",
       "1    0.101679\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "display(df.info())\n",
    "df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных 2 стобца, 159571 строк, безпропусков, целевой признак имеет явный дисбаланс классов, учтем при построении моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    return ' '.join((re.sub(r'[^a-zA-Z]', ' ', text)).lower().split())\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_text(text):\n",
    "    text_clear = clear_text(text)\n",
    "    text_token = word_tokenize(text_clear)\n",
    "    text_token_without_stop_words = [\n",
    "        word for word in text_token if word not in stop_words]\n",
    "    lemma = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in text_token_without_stop_words]\n",
    "    \n",
    "    return \" \".join(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8864112554024993bc02d0623669ef02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=159571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['lemm_text'] = df['text'].progress_apply(lambda x: lemm_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, test = train_test_split(df, test_size=0.2, random_state=13, stratify=df['toxic'])\n",
    "train, valid = train_test_split(df_train, test_size=0.25, random_state=13, stratify=df_train['toxic'])\n",
    "\n",
    "target_train = train['toxic']\n",
    "target_valid = valid['toxic']\n",
    "target_test = test['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы обучающей выборки: (95742, 111654)\n",
      "Размер матрицы валидационной выборки: (31914, 111654)\n",
      "Размер матрицы тестовой выборки: (31915, 111654)\n"
     ]
    }
   ],
   "source": [
    "corpus = train['lemm_text'].values.astype('U')\n",
    "\n",
    "count_tf_idf = TfidfVectorizer() \n",
    "features_train = count_tf_idf.fit_transform(corpus)\n",
    "\n",
    "features_valid = count_tf_idf.transform(valid['lemm_text'].values.astype('U')) \n",
    "features_test = count_tf_idf.transform(test['lemm_text'].values.astype('U')) \n",
    "\n",
    "print(\"Размер матрицы обучающей выборки:\", features_train.shape)\n",
    "print(\"Размер матрицы валидационной выборки:\", features_valid.shape)\n",
    "print(\"Размер матрицы тестовой выборки:\", features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 1s, sys: 7min 27s, total: 13min 28s\n",
      "Wall time: 13min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight='balanced', cv=3, dual=False,\n",
       "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
       "                     max_iter=100, multi_class='warn', n_jobs=None,\n",
       "                     penalty='l2', random_state=12345, refit=True, scoring=None,\n",
       "                     solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegressionCV(cv=3, random_state=12345, class_weight='balanced')\n",
    "lr.fit(features_train, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(model, features, target):\n",
    "    prediction = model.predict(features)\n",
    "    f1 = f1_score(target, prediction)\n",
    "    print('F1-мера: {:.3f}'.format(f1))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера: 0.764\n",
      "F1-мера: 0.755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7547169811320755"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(lr, features_valid, target_valid)\n",
    "pred(lr,features_test,target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия справилась с задачей метрика  F1 =  0.755 на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "rfc = RandomForestClassifier(random_state=12345, class_weight='balanced')\n",
    "parametrs = { 'n_estimators': range (10, 51, 10),\n",
    "              'max_depth': range (1,13, 2),\n",
    "              'min_samples_leaf': range (1,8),\n",
    "              'min_samples_split': range (2,10,2) }\n",
    "\n",
    "gs_rfc = GridSearchCV(rfc, parametrs, scoring='f1',cv=3)\n",
    "gs_rfc.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гридсерч выдал лучшие параметры:\n",
    "                             random_state=12345, \n",
    "                             class_weight='balanced',\n",
    "                             max_depth=11, \n",
    "                             min_samples_leaf=1, \n",
    "                             min_samples_split=4,\n",
    "                             n_estimators=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.32 s, sys: 0 ns, total: 1.32 s\n",
      "Wall time: 1.32 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=11, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=40, n_jobs=None, oob_score=False,\n",
       "                       random_state=12345, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rfc = RandomForestClassifier(random_state=12345, \n",
    "                             class_weight='balanced',\n",
    "                             max_depth=11, \n",
    "                             min_samples_leaf=1, \n",
    "                             min_samples_split=4,\n",
    "                             n_estimators=40)\n",
    "rfc.fit(features_train, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера: 0.399\n",
      "F1-мера: 0.392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3922877271041898"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(rfc, features_valid, target_valid)\n",
    "pred(rfc,features_test,target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рандомный лес с задачей не справился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С задачей справилась модель Логистическрой регресси метрика F1=0,75 , Рандомный лес не справился с задаче, показав очень низкий результат 0.392. \n",
    "\n",
    "Для ревьюера: пытался использовать  BERT, в итоге отказался от этой идеии т.к. мой старичек(мак) не тянет, также пытался использовать катбусткласификатор, но он просто убивает кернел(, мне кажется градиетныйбустинг лучше бы справился с задачей по качеству метрики"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2419,
    "start_time": "2021-09-30T17:13:21.747Z"
   },
   {
    "duration": 621,
    "start_time": "2021-09-30T17:13:58.126Z"
   },
   {
    "duration": 661,
    "start_time": "2021-09-30T17:14:14.774Z"
   },
   {
    "duration": 646,
    "start_time": "2021-09-30T17:15:30.361Z"
   },
   {
    "duration": 13,
    "start_time": "2021-09-30T17:21:11.937Z"
   },
   {
    "duration": 292,
    "start_time": "2021-09-30T17:25:40.032Z"
   },
   {
    "duration": 33,
    "start_time": "2021-09-30T17:25:47.387Z"
   },
   {
    "duration": 34,
    "start_time": "2021-09-30T17:29:08.034Z"
   },
   {
    "duration": 42,
    "start_time": "2021-09-30T17:29:57.863Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-30T17:31:58.322Z"
   },
   {
    "duration": 1469,
    "start_time": "2021-09-30T17:34:06.037Z"
   },
   {
    "duration": 37,
    "start_time": "2021-09-30T17:37:32.811Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-30T17:37:33.695Z"
   },
   {
    "duration": 8,
    "start_time": "2021-09-30T17:37:34.930Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-30T17:39:57.646Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-30T17:40:25.088Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-30T17:40:25.824Z"
   },
   {
    "duration": 11,
    "start_time": "2021-09-30T17:40:28.078Z"
   },
   {
    "duration": 756044,
    "start_time": "2021-09-30T17:40:42.961Z"
   },
   {
    "duration": 13,
    "start_time": "2021-09-30T17:53:34.137Z"
   },
   {
    "duration": 157,
    "start_time": "2021-09-30T18:01:52.614Z"
   },
   {
    "duration": 9058,
    "start_time": "2021-09-30T18:03:04.858Z"
   },
   {
    "duration": 1989,
    "start_time": "2021-09-30T18:04:33.648Z"
   },
   {
    "duration": 700,
    "start_time": "2021-09-30T18:04:35.639Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-30T18:04:36.341Z"
   },
   {
    "duration": 6,
    "start_time": "2021-09-30T18:04:36.348Z"
   },
   {
    "duration": 755747,
    "start_time": "2021-09-30T18:04:36.356Z"
   },
   {
    "duration": 13,
    "start_time": "2021-09-30T18:17:12.104Z"
   },
   {
    "duration": 192,
    "start_time": "2021-09-30T18:17:12.118Z"
   },
   {
    "duration": 8813,
    "start_time": "2021-09-30T18:17:12.312Z"
   },
   {
    "duration": 2150708,
    "start_time": "2021-09-30T18:39:08.320Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-30T19:17:52.363Z"
   },
   {
    "duration": 20,
    "start_time": "2021-09-30T19:18:24.890Z"
   },
   {
    "duration": 35,
    "start_time": "2021-09-30T19:19:47.355Z"
   },
   {
    "duration": 160,
    "start_time": "2021-09-30T19:27:19.196Z"
   },
   {
    "duration": 2016,
    "start_time": "2021-09-30T19:29:27.992Z"
   },
   {
    "duration": 671,
    "start_time": "2021-09-30T19:29:30.010Z"
   },
   {
    "duration": 18,
    "start_time": "2021-09-30T19:29:30.685Z"
   },
   {
    "duration": 14,
    "start_time": "2021-09-30T19:29:30.705Z"
   },
   {
    "duration": 774793,
    "start_time": "2021-09-30T19:29:30.721Z"
   },
   {
    "duration": 184,
    "start_time": "2021-09-30T19:42:25.516Z"
   },
   {
    "duration": 8627,
    "start_time": "2021-09-30T19:42:25.703Z"
   },
   {
    "duration": 756770,
    "start_time": "2021-09-30T19:42:34.332Z"
   },
   {
    "duration": 3,
    "start_time": "2021-09-30T19:55:11.104Z"
   },
   {
    "duration": 33,
    "start_time": "2021-09-30T19:55:11.109Z"
   },
   {
    "duration": 5,
    "start_time": "2021-09-30T20:11:42.009Z"
   },
   {
    "duration": 6056296,
    "start_time": "2021-09-30T20:13:12.550Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-30T22:06:16.548Z"
   },
   {
    "duration": 4,
    "start_time": "2021-09-30T22:08:50.715Z"
   },
   {
    "duration": 1281,
    "start_time": "2021-09-30T22:09:29.454Z"
   },
   {
    "duration": 419,
    "start_time": "2021-09-30T22:10:11.901Z"
   },
   {
    "duration": 3338,
    "start_time": "2021-10-01T10:05:37.806Z"
   },
   {
    "duration": 672,
    "start_time": "2021-10-01T10:05:41.146Z"
   },
   {
    "duration": 5,
    "start_time": "2021-10-01T10:05:41.823Z"
   },
   {
    "duration": 20,
    "start_time": "2021-10-01T10:05:41.830Z"
   },
   {
    "duration": 802887,
    "start_time": "2021-10-01T10:05:41.852Z"
   },
   {
    "duration": 200,
    "start_time": "2021-10-01T10:19:04.741Z"
   },
   {
    "duration": 9638,
    "start_time": "2021-10-01T10:19:04.944Z"
   },
   {
    "duration": 808690,
    "start_time": "2021-10-01T10:19:14.584Z"
   },
   {
    "duration": 8,
    "start_time": "2021-10-01T10:32:43.352Z"
   },
   {
    "duration": 43,
    "start_time": "2021-10-01T10:32:43.364Z"
   },
   {
    "duration": 354,
    "start_time": "2021-10-01T10:32:43.408Z"
   },
   {
    "duration": -215,
    "start_time": "2021-10-01T10:32:43.980Z"
   },
   {
    "duration": -216,
    "start_time": "2021-10-01T10:32:43.982Z"
   },
   {
    "duration": 1323,
    "start_time": "2021-10-01T10:43:53.087Z"
   },
   {
    "duration": 416,
    "start_time": "2021-10-01T10:44:03.543Z"
   },
   {
    "duration": 89,
    "start_time": "2021-10-01T11:07:58.676Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
